Alpha_Beta_puring_minimax
First, observe the Tic Tac Toe game. This is an adversarial search problem. We first thought of using Minmax, hoping to minimize the chance of failure and maximize the chance of winning. We set the reward for our victory to 100, and the opponent wins. The reward is set to -100, and the draw is 0, so we generate nodes by calculating the heuristic and using backtracking to solve the problem. The heuristic here is the longest distance returned to yourself or the opponent. If the opponent's distance in line with the distance of the game's rules is longer, turn its distance into a negative number.
Due to the easy use of Minmax, as the board increases, the speed will become slower and slower, so we tried the depth-limited search. However, because the limited depth will reduce the accuracy, we need to weigh the depth and accuracy, so we choose to limit the depth to a depth of 4.
At the same time, we found that using Alpha-beta Pruning will also significantly improve the speed because it will reduce the number of nodes to try. First, we judge whether there has been a win or loss. If not, but the depth equals 4, then return directly to reward. Then the players take turns swapping, using backtracking to solve the problem. Moreover, use Alpha and Beta to determine whether to return to the node directly.
